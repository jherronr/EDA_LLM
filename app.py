
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import io
import os
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.chains import LLMChain

# Configuraci√≥n visual de los gr√°ficos
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)

# Configurar el t√≠tulo y la descripci√≥n de la aplicaci√≥n
st.title('üìä Herramienta de An√°lisis de Datos y Asistente LLM')
st.write('Sube un archivo CSV para generar un an√°lisis completo y chatear con un LLM sobre tus datos.')

# Inicializar el historial del chat, el DataFrame y la conclusi√≥n en la sesi√≥n
if "messages" not in st.session_state:
    st.session_state.messages = []
    
if "df" not in st.session_state:
    st.session_state.df = None

if "initial_conclusion" not in st.session_state:
    st.session_state.initial_conclusion = None

# Aceptar la entrada del archivo por el usuario
uploaded_file = st.file_uploader("Elige un archivo CSV", type="csv")

if uploaded_file is not None and st.session_state.df is None:
    try:
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
        st.success("‚úÖ Archivo cargado exitosamente.")
        
        # ----------------------------------------------------
        # Parte 1: Resumen y Estad√≠sticas
        # ----------------------------------------------------
        st.header('üîç Resumen de los Datos')
        
        st.subheader('Informaci√≥n General')
        buffer = io.StringIO()
        df.info(buf=buffer)
        s = buffer.getvalue()
        st.text(s)
        
        st.subheader('Primeras 5 Filas')
        st.dataframe(df.head())
        
        st.subheader('Estad√≠sticas Descriptivas')
        st.dataframe(df.describe().T)
        
        st.subheader('Valores Nulos y Duplicados')
        st.write("Conteo de valores nulos por columna:")
        st.dataframe(df.isnull().sum())
        st.write(f"Total de filas duplicadas: **{df.duplicated().sum()}**")
        
        # ----------------------------------------------------
        # Parte 2: Visualizaciones del EDA
        # ----------------------------------------------------
        st.header('üìà Visualizaciones de los Datos')
        
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        cat_cols = df.select_dtypes(include='object').columns
        
        if not numeric_cols.empty:
            st.subheader('Distribuci√≥n de Variables Num√©ricas')
            for col in numeric_cols:
                fig, ax = plt.subplots()
                sns.histplot(df[col], kde=True, ax=ax)
                ax.set_title(f'Histograma de {col}')
                st.pyplot(fig)
                
                fig, ax = plt.subplots()
                sns.boxplot(x=df[col], ax=ax)
                ax.set_title(f'Boxplot de {col}')
                st.pyplot(fig)

        if not cat_cols.empty:
            st.subheader('Distribuci√≥n de Variables Categ√≥ricas')
            for col in cat_cols:
                fig, ax = plt.subplots()
                sns.countplot(y=df[col], order=df[col].value_counts().index, ax=ax)
                ax.set_title(f'Conteo de {col}')
                st.pyplot(fig)
        
        if len(numeric_cols) > 1:
            st.subheader('Matriz de Correlaci√≥n')
            fig, ax = plt.subplots()
            corr_matrix = df[numeric_cols].corr()
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)
            ax.set_title('Matriz de Correlaci√≥n entre Variables Num√©ricas')
            st.pyplot(fig)
            
        # ----------------------------------------------------
        # Parte 3: Generar Conclusi√≥n Inicial del LLM
        # ----------------------------------------------------
        # Obtener la clave de API de las variables de entorno o de los "secrets" de Streamlit Cloud
        if "GROQ_API_KEY" in os.environ:
            with st.spinner('Generando conclusi√≥n inicial sobre el dataset...'):
                df_string = df.to_string(index=False)
                system_prompt_initial = (
                    "Eres un analista de datos experto. Tienes un dataset en formato de texto a continuaci√≥n. "
                    "Analiza el dataset, extrae los insights m√°s relevantes y proporciona una conclusi√≥n concisa y directa. "
                    "No incluyas nada m√°s en tu respuesta. "
                    "Dataset:\n"
                    "```\n"
                    f"{df_string}\n"
                    "```"
                )
                
                llm = ChatGroq(
                    temperature=0,
                    groq_api_key=os.environ["GROQ_API_KEY"],
                    model_name="gemma2-9b-it"
                )
                
                initial_prompt_template = ChatPromptTemplate.from_messages(
                    [("system", system_prompt_initial)]
                )
                
                initial_llm_chain = LLMChain(prompt=initial_prompt_template, llm=llm)
                
                st.session_state.initial_conclusion = initial_llm_chain.invoke({})['text']
        else:
            st.session_state.initial_conclusion = "No se pudo generar la conclusi√≥n. Por favor, configura tu clave de API de Groq en los 'secrets' de Streamlit Cloud."

    except Exception as e:
        st.error(f"Ocurri√≥ un error al procesar el archivo: {e}")
        st.stop()
        
if st.session_state.df is not None:
    # ----------------------------------------------------
    # Secci√≥n de Conclusi√≥n
    # ----------------------------------------------------
    st.markdown("---")
    st.header('üí° Conclusi√≥n del An√°lisis de Datos')
    if st.session_state.initial_conclusion:
        st.info(st.session_state.initial_conclusion)

    # ----------------------------------------------------
    # Secci√≥n de Chat Interactivo
    # ----------------------------------------------------
    st.markdown("---")
    st.header('ü§ñ Asistente LLM sobre tus Datos')
    st.write('Pregunta lo que quieras sobre el an√°lisis de datos que acabas de ver.')
    
    # Mostrar los mensajes anteriores del chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    df_string = st.session_state.df.to_string(index=False)
    
    # Crear el prompt del sistema para las preguntas interactivas
    system_prompt_qa = (
        "Eres un analista de datos experto. Tienes un dataset en formato de texto a continuaci√≥n. "
        "Analiza el dataset y responde a las preguntas del usuario. "
        "S√© conciso y ve al punto. No inventes informaci√≥n. "
        "Dataset:\n"
        "```\n"
        f"{df_string}\n"
        "```"
    )

    # Aceptar la entrada del usuario
    if prompt := st.chat_input("Pregunta sobre tu dataset..."):
        # A√±adir el mensaje del usuario al historial
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                if "GROQ_API_KEY" in os.environ:
                    llm = ChatGroq(
                        temperature=0,
                        groq_api_key=os.environ["GROQ_API_KEY"],
                        model_name="gemma2-9b-it"
                    )
                    
                    prompt_template_qa = ChatPromptTemplate.from_messages(
                        [("system", system_prompt_qa), ("human", "{user_question}")]
                    )
                    
                    llm_chain = LLMChain(prompt=prompt_template_qa, llm=llm)
                    
                    response = llm_chain.invoke({"user_question": prompt})['text']
                    
                    st.markdown(response)
                    
                    st.session_state.messages.append({"role": "assistant", "content": response})

                else:
                    st.warning("¬°Advertencia! La clave de API de Groq no est√° configurada.")
                    st.info("Para que el LLM funcione, debes configurar tu clave de API en los 'secrets' de Streamlit Cloud con el nombre 'GROQ_API_KEY'.")
                    st.warning("Respuesta simulada del LLM para demostraci√≥n.")
                    
                    if "promedio" in prompt.lower():
                        if "Amount" in st.session_state.df.columns:
                            response = f"El monto promedio de las transacciones es de ${st.session_state.df['Amount'].mean():.2f}."
                        else:
                            response = "No se encontr√≥ la columna 'Amount'."
                    else:
                        response = "No puedo responder a esa pregunta con los datos disponibles."
                    
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})

            except Exception as e:
                st.error(f"Ocurri√≥ un error al llamar al modelo LLM: {e}")
                st.warning("Aseg√∫rate de que la clave de API es v√°lida y el modelo est√° disponible.")
